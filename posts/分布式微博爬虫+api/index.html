<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><style>:root{--accent-color:#FF4D4D;--font-size:17.5px}</style><title>分布式微博爬虫+API</title>
<meta name=description content="前言 WeiboScraper是采用Python后端开发和爬虫能力设计的一个项目，目标是爬取微博公开的话题数据，存下来做简单分析，再通过API提供查询功能。
需求分析 目标需求 爬取数据：从微博抓取公开话题数据，包括热门话题、用户信息（ID、昵称）、帖子内容、发布时间和点赞数。 数据存储：存到数据库，方便后续处理和查 …"><meta name=keywords content='blog,hugo,Python,爬虫,API'><meta property="og:url" content="https://merthon.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E5%8D%9A%E7%88%AC%E8%99%AB+api/"><meta property="og:type" content="website"><meta property="og:title" content="分布式微博爬虫+API"><meta property="og:description" content="前言 WeiboScraper是采用Python后端开发和爬虫能力设计的一个项目，目标是爬取微博公开的话题数据，存下来做简单分析，再通过API提供查询功能。
需求分析 目标需求 爬取数据：从微博抓取公开话题数据，包括热门话题、用户信息（ID、昵称）、帖子内容、发布时间和点赞数。 数据存储：存到数据库，方便后续处理和查 …"><meta property="og:image" content="https://merthon.github.io/images/cat.webp"><meta property="og:image:secure_url" content="https://merthon.github.io/images/cat.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="分布式微博爬虫+API"><meta name=twitter:description content="前言 WeiboScraper是采用Python后端开发和爬虫能力设计的一个项目，目标是爬取微博公开的话题数据，存下来做简单分析，再通过API提供查询功能。
需求分析 目标需求 爬取数据：从微博抓取公开话题数据，包括热门话题、用户信息（ID、昵称）、帖子内容、发布时间和点赞数。 数据存储：存到数据库，方便后续处理和查 …"><meta property="twitter:domain" content="https://merthon.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E5%8D%9A%E7%88%AC%E8%99%AB+api/"><meta property="twitter:url" content="https://merthon.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E5%8D%9A%E7%88%AC%E8%99%AB+api/"><meta name=twitter:image content="https://merthon.github.io/images/cat.webp"><link rel=canonical href=https://merthon.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E5%8D%9A%E7%88%AC%E8%99%AB+api/><link rel=stylesheet type=text/css href=/css/normalize.min.css media=print><link rel=stylesheet type=text/css href=/css/main.min.css><link id=dark-theme rel=stylesheet href=/css/dark.min.css><script src=/js/bundle.min.275fedb6f364c8865658bae576d82b514ace973f6a13ed63503a85b20c697453.js integrity="sha256-J1/ttvNkyIZWWLrldtgrUUrOlz9qE+1jUDqFsgxpdFM="></script></head><body><script>setThemeByUserPref()</script><header class=header><nav class=header-nav><div class=avatar><a href=https://merthon.github.io/><img src=/images/cat.webp alt=cat></a></div><div class=nav-title><a class=nav-brand href=https://merthon.github.io/>Merthon</a></div><div class=nav-links><div class=nav-link><a href=https://merthon.github.io/ aria-label><span data-feather=home></span> Home</a></div><div class=nav-link><a href=https://merthon.github.io/posts/ aria-label><span data-feather=book></span> Posts</a></div><div class=nav-link><a href=https://merthon.github.io/projects/ aria-label><span data-feather=code></span> Projects</a></div><div class=nav-link><a href=https://merthon.github.io/tags/ aria-label><span data-feather=tag></span> Tags</a></div><div class=nav-link><a href=https://github.com/Merthon aria-label=github><span data-feather=github></span></a></div><span class=nav-icons-divider></span><div class="nav-link dark-theme-toggle"><span class="sr-only dark-theme-toggle-screen-reader-target">theme</span>
<a aria-hidden=true role=switch><span class=theme-toggle-icon data-feather=moon></span></a></div><div class=nav-link id=hamburger-menu-toggle><span class="sr-only hamburger-menu-toggle-screen-reader-target">menu</span>
<a aria-checked=false aria-labelledby=hamburger-menu-toggle id=hamburger-menu-toggle-target role=switch><span data-feather=menu></span></a></div><ul class="nav-hamburger-list visibility-hidden"><li class=nav-item><a href=https://merthon.github.io/><span data-feather=home></span> Home</a></li><li class=nav-item><a href=https://merthon.github.io/posts/><span data-feather=book></span> Posts</a></li><li class=nav-item><a href=https://merthon.github.io/projects/><span data-feather=code></span> Projects</a></li><li class=nav-item><a href=https://merthon.github.io/tags/><span data-feather=tag></span> Tags</a></li><li class=nav-item><a href=https://github.com/Merthon><span data-feather=github></span></a></li><li class="nav-item dark-theme-toggle"><span class="sr-only dark-theme-toggle-screen-reader-target">theme</span>
<a role=switch><span class=theme-toggle-icon data-feather=moon></span></a></li></ul></div></nav></header><main id=content><div class="post container"><div class=post-header-section><h1>分布式微博爬虫+API</h1><small role=doc-subtitle></small><p class=post-date>March 14, 2025</p><ul class=post-tags><li class=post-tag><a href=https://merthon.github.io/tags/python>Python</a></li><li class=post-tag><a href=https://merthon.github.io/tags/%E7%88%AC%E8%99%AB>爬虫</a></li><li class=post-tag><a href=https://merthon.github.io/tags/api>API</a></li></ul></div><div class=post-content><h1 id=前言>前言</h1><p>WeiboScraper是采用Python后端开发和爬虫能力设计的一个项目，目标是爬取微博公开的话题数据，存下来做简单分析，再通过API提供查询功能。</p><h1 id=需求分析>需求分析</h1><h2 id=目标需求>目标需求</h2><ul><li><strong>爬取数据</strong>：从微博抓取公开话题数据，包括热门话题、用户信息（ID、昵称）、帖子内容、发布时间和点赞数。</li><li><strong>数据存储</strong>：存到数据库，方便后续处理和查询。</li><li><strong>API服务</strong>：搭一个后端API，让用户能查爬到的数据，比如按话题或用户ID查询。</li></ul><h2 id=功能需求>功能需求</h2><ul><li><strong>爬虫</strong>：支持多个话题的爬取，能翻页，抗封能力（后续会加代理，暂时没有）。</li><li><strong>存储</strong>：使用MongoDB存储数据，加话题字段区分来源。</li><li><strong>API</strong>：支持GET请求，按条件返回JSON。</li></ul><h1 id=技术方案>技术方案</h1><h2 id=技术>技术</h2><ul><li><strong>Python</strong>：核心语言，生态丰富。</li><li><strong>Scrapy</strong>：爬虫框架，高效解析网页。</li><li><strong>Scrapy-Redis</strong>：分布式扩展，用Redis做任务队列和去重。</li><li><strong>MongoDB</strong>：NoSQL数据库，存JSON格式数据。</li><li><strong>FastAPI</strong>：后端API框架，轻量、异步、自带文档。</li></ul><h2 id=流程>流程</h2><ul><li>Redis塞初始URL → Scrapy爬取 → 数据存MongoDB。</li><li>FastAPI连MongoDB → 响应用户请求。</li></ul><h1 id=核心代码>核心代码</h1><h2 id=实现爬虫功能weibopy>实现爬虫功能weibo.py</h2><p>从Redis取URL，解析话题页，抓帖子，分页爬取，加异常处理。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> scrapy
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> scrapy_redis.spiders <span style=color:#f92672>import</span> RedisSpider
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> WeiboScraper.items <span style=color:#f92672>import</span> WeiboItem
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> urllib.parse <span style=color:#f92672>import</span> parse_qs, urlparse
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>WeiboSpider</span>(RedisSpider):
</span></span><span style=display:flex><span>    name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;weibo&#39;</span>
</span></span><span style=display:flex><span>    allowed_domains <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;s.weibo.com&#39;</span>]
</span></span><span style=display:flex><span>    redis_key <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;weibo:start_urls&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parse</span>(self, response):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> response<span style=color:#f92672>.</span>status <span style=color:#f92672>!=</span> <span style=color:#ae81ff>200</span>:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Error: </span><span style=color:#e6db74>{</span>response<span style=color:#f92672>.</span>url<span style=color:#e6db74>}</span><span style=color:#e6db74> 返回 </span><span style=color:#e6db74>{</span>response<span style=color:#f92672>.</span>status<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span>
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;URL:&#34;</span>, response<span style=color:#f92672>.</span>url)
</span></span><span style=display:flex><span>        topic <span style=color:#f92672>=</span> parse_qs(urlparse(response<span style=color:#f92672>.</span>url)<span style=color:#f92672>.</span>query)<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;q&#39;</span>, [<span style=color:#e6db74>&#39;unknown&#39;</span>])[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        posts <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>css(<span style=color:#e6db74>&#39;div.card-wrap&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> post <span style=color:#f92672>in</span> posts:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>                item <span style=color:#f92672>=</span> WeiboItem()
</span></span><span style=display:flex><span>                item[<span style=color:#e6db74>&#39;user_id&#39;</span>] <span style=color:#f92672>=</span> post<span style=color:#f92672>.</span>css(<span style=color:#e6db74>&#39;a.name::attr(href)&#39;</span>)<span style=color:#f92672>.</span>get(default<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;unknown&#39;</span>)<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;/&#39;</span>)[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;?&#39;</span>)[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>                item[<span style=color:#e6db74>&#39;nickname&#39;</span>] <span style=color:#f92672>=</span> post<span style=color:#f92672>.</span>css(<span style=color:#e6db74>&#39;a.name::text&#39;</span>)<span style=color:#f92672>.</span>get(default<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;unknown&#39;</span>)
</span></span><span style=display:flex><span>                item[<span style=color:#e6db74>&#39;content&#39;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;&#39;</span><span style=color:#f92672>.</span>join(post<span style=color:#f92672>.</span>css(<span style=color:#e6db74>&#39;p.txt::text&#39;</span>)<span style=color:#f92672>.</span>getall())<span style=color:#f92672>.</span>strip() <span style=color:#f92672>or</span> <span style=color:#e6db74>&#39;N/A&#39;</span>
</span></span><span style=display:flex><span>                item[<span style=color:#e6db74>&#39;post_time&#39;</span>] <span style=color:#f92672>=</span> post<span style=color:#f92672>.</span>css(<span style=color:#e6db74>&#39;p.from a:first-child::text&#39;</span>)<span style=color:#f92672>.</span>get(default<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;N/A&#39;</span>)<span style=color:#f92672>.</span>strip()
</span></span><span style=display:flex><span>                item[<span style=color:#e6db74>&#39;likes&#39;</span>] <span style=color:#f92672>=</span> post<span style=color:#f92672>.</span>css(<span style=color:#e6db74>&#39;span.woo-like-count::text&#39;</span>)<span style=color:#f92672>.</span>get(default<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;0&#39;</span>)
</span></span><span style=display:flex><span>                item[<span style=color:#e6db74>&#39;topic&#39;</span>] <span style=color:#f92672>=</span> topic
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>yield</span> item
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>                print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;解析错误: </span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 下一页</span>
</span></span><span style=display:flex><span>        next_page <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>css(<span style=color:#e6db74>&#39;a.next::attr(href)&#39;</span>)<span style=color:#f92672>.</span>get()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> next_page:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>yield</span> scrapy<span style=color:#f92672>.</span>Request(response<span style=color:#f92672>.</span>urljoin(next_page), callback<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>parse)
</span></span></code></pre></div><h2 id=数据管道pipelinespy>数据管道：pipelines.py</h2><p>连接MongoDB，存数据，关闭连接。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> pymongo <span style=color:#f92672>import</span> MongoClient
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>WeiboScraperPipeline</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>client <span style=color:#f92672>=</span> MongoClient(<span style=color:#e6db74>&#39;localhost&#39;</span>, <span style=color:#ae81ff>27017</span>, username<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;自己的&#39;</span>, password<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;自己的&#39;</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>db <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>client[<span style=color:#e6db74>&#39;weibo_db&#39;</span>]
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>collection <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>db[<span style=color:#e6db74>&#39;posts&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>process_item</span>(self, item, spider):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>collection<span style=color:#f92672>.</span>insert_one(dict(item))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> item
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>close_spider</span>(self, spider):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>client<span style=color:#f92672>.</span>close()
</span></span></code></pre></div><h2 id=apiapipy>API：api.py</h2><p>FastAPI提供俩端点，查帖子和用户数据。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> fastapi <span style=color:#f92672>import</span> FastAPI
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pymongo <span style=color:#f92672>import</span> MongoClient
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pydantic <span style=color:#f92672>import</span> BaseModel
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> List, Optional
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>app <span style=color:#f92672>=</span> FastAPI()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>client <span style=color:#f92672>=</span> MongoClient(<span style=color:#e6db74>&#39;localhost&#39;</span>, <span style=color:#ae81ff>27017</span>, username<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;admin&#39;</span>, password<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;admin&#39;</span>)
</span></span><span style=display:flex><span>db <span style=color:#f92672>=</span> client[<span style=color:#e6db74>&#39;weibo_db&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Post</span>(BaseModel):
</span></span><span style=display:flex><span>    user_id: str
</span></span><span style=display:flex><span>    nickname: str
</span></span><span style=display:flex><span>    content: str
</span></span><span style=display:flex><span>    post_time: str
</span></span><span style=display:flex><span>    likes: str
</span></span><span style=display:flex><span>    topic: str
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@app.get</span>(<span style=color:#e6db74>&#34;/posts/&#34;</span>, response_model<span style=color:#f92672>=</span>List[Post])
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_posts</span>(topic: Optional[str] <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>, limit: int <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>    query <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;topic&#39;</span>: topic} <span style=color:#66d9ef>if</span> topic <span style=color:#66d9ef>else</span> {}
</span></span><span style=display:flex><span>    posts <span style=color:#f92672>=</span> list(db<span style=color:#f92672>.</span>posts<span style=color:#f92672>.</span>find(query)<span style=color:#f92672>.</span>limit(limit))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> [Post(<span style=color:#f92672>**</span>post) <span style=color:#66d9ef>for</span> post <span style=color:#f92672>in</span> posts]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@app.get</span>(<span style=color:#e6db74>&#34;/posts/</span><span style=color:#e6db74>{user_id}</span><span style=color:#e6db74>&#34;</span>, response_model<span style=color:#f92672>=</span>List[Post])
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_user_posts</span>(user_id: str, limit: int <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>    posts <span style=color:#f92672>=</span> list(db<span style=color:#f92672>.</span>posts<span style=color:#f92672>.</span>find({<span style=color:#e6db74>&#39;user_id&#39;</span>: user_id})<span style=color:#f92672>.</span>limit(limit))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> [Post(<span style=color:#f92672>**</span>post) <span style=color:#66d9ef>for</span> post <span style=color:#f92672>in</span> posts]
</span></span></code></pre></div><h2 id=配置settingspy部分>配置：settings.py（部分）</h2><p>配置分布式、限速、管道。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 加入redis</span>
</span></span><span style=display:flex><span>EDIS_HOST <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;localhost&#39;</span>
</span></span><span style=display:flex><span>REDIS_PORT <span style=color:#f92672>=</span> <span style=color:#ae81ff>6379</span>
</span></span><span style=display:flex><span>SCHEDULER <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;scrapy_redis.scheduler.Scheduler&#34;</span>
</span></span><span style=display:flex><span>DUPEFILTER_CLASS <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;scrapy_redis.dupefilter.RFPDupeFilter&#34;</span>
</span></span><span style=display:flex><span>SCHEDULER_PERSIST <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>BOT_NAME <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;WeiboScraper&#34;</span>
</span></span><span style=display:flex><span>DOWNLOADER_MIDDLEWARES <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;</span>: <span style=color:#66d9ef>None</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>SPIDER_MODULES <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;WeiboScraper.spiders&#34;</span>]
</span></span><span style=display:flex><span>NEWSPIDER_MODULE <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;WeiboScraper.spiders&#34;</span>
</span></span><span style=display:flex><span>COOKIES_ENABLED <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 伪装浏览器</span>
</span></span><span style=display:flex><span>DEFAULT_REQUEST_HEADERS <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;User-Agent&#39;</span>: <span style=color:#e6db74>&#39;自己电脑的user-agent&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Accept&#39;</span>: <span style=color:#e6db74>&#39;浏览器自己F12查看添加&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Accept-Language&#39;</span>: <span style=color:#e6db74>&#39;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Referer&#39;</span>: <span style=color:#e6db74>&#39;https://s.weibo.com/&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Cookie&#39;</span>: <span style=color:#e6db74>&#39;登录以后自己的cookie&#39;</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#75715e># 下载延迟，防封</span>
</span></span><span style=display:flex><span>DOWNLOAD_DELAY <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>CONCURRENT_REQUESTS <span style=color:#f92672>=</span> <span style=color:#ae81ff>8</span>  <span style=color:#75715e># redis单机不能太高</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 开启Item Pipeline（存MongoDB用）</span>
</span></span><span style=display:flex><span>ITEM_PIPELINES <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;WeiboScraper.pipelines.WeiboScraperPipeline&#39;</span>: <span style=color:#ae81ff>300</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>TWISTED_REACTOR <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;twisted.internet.asyncioreactor.AsyncioSelectorReactor&#34;</span>
</span></span><span style=display:flex><span>FEED_EXPORT_ENCODING <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;utf-8&#34;</span>
</span></span><span style=display:flex><span>LOG_LEVEL <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;INFO&#39;</span>
</span></span></code></pre></div><h1 id=结语>结语</h1><p>从零搭起来，解决了MongoDB数据库连接问题、数据不全以及出现登录问题、分布式单机等问题，最终实现了爬取、存储、分析和API服务全流程。下一步就是增加评论爬取、前端展示。</p><h1 id=项目地址>项目地址</h1><p><a href=https://github.com/Merthon/WeiboScraper>https://github.com/Merthon/WeiboScraper</a></p></div><div class=prev-next></div><svg id="btt-button" class="arrow-logo" height="1em" viewBox="0 0 384 512" onclick="scrollToTop()" title="Go to top"><path d="M177 159.7l136 136c9.4 9.4 9.4 24.6.0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9.0L160 255.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9.0L7 329.7c-9.4-9.4-9.4-24.6.0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1z"/></svg>
<script>let backToTopButton=document.getElementById("btt-button");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?backToTopButton.style.display="block":backToTopButton.style.display="none"}function scrollToTop(){window.scrollTo(0,0)}</script></div><aside class=post-toc><nav id=toc><nav id=TableOfContents><ul><li><a href=#前言>前言</a></li><li><a href=#需求分析>需求分析</a><ul><li><a href=#目标需求>目标需求</a></li><li><a href=#功能需求>功能需求</a></li></ul></li><li><a href=#技术方案>技术方案</a><ul><li><a href=#技术>技术</a></li><li><a href=#流程>流程</a></li></ul></li><li><a href=#核心代码>核心代码</a><ul><li><a href=#实现爬虫功能weibopy>实现爬虫功能weibo.py</a></li><li><a href=#数据管道pipelinespy>数据管道：pipelines.py</a></li><li><a href=#apiapipy>API：api.py</a></li><li><a href=#配置settingspy部分>配置：settings.py（部分）</a></li></ul></li><li><a href=#结语>结语</a></li><li><a href=#项目地址>项目地址</a></li></ul></nav></nav></aside></main><footer class=footer><span>&copy; 2025 Merthon</span>
<span>Made with &#10084;&#65039; Hugo</span></footer></body></html>